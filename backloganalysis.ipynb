{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n"
      ],
      "metadata": {
        "id": "xBE9Wx1xb1Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] =\"sk-...\""
      ],
      "metadata": {
        "id": "sG95bMJsc5qX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show langchain"
      ],
      "metadata": {
        "id": "QJCv-S8h3vaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get CSV Data\n",
        "\n",
        "NOTE: this gets data from Google Drive"
      ],
      "metadata": {
        "id": "3BY9pRm_6Zgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/.../ado_backlog.csv')"
      ],
      "metadata": {
        "id": "YjpS2d7J5dKw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "h_doGHhH5oYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CSV Agent\n",
        "\n",
        "NOTE: CSV Agent was moved to langchain experimental (https://github.com/langchain-ai/langchain/discussions/11680). This agent calls the Pandas DataFrame agent under the hood, which in turn calls the Python agent, which executes LLM generated Python code - this can be bad if the LLM generated Python code is harmful. Use cautiously."
      ],
      "metadata": {
        "id": "xxNrC8XL7X8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_experimental"
      ],
      "metadata": {
        "id": "wl_a-7008zfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.agents.agent_toolkits.csv.base import create_csv_agent\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "2bFXsGBQ7cSm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_csv_agent(OpenAI(temperature=0),\n",
        "                         '/content/drive/MyDrive/.../ado_backlog.csv',\n",
        "                         verbose=True)"
      ],
      "metadata": {
        "id": "Am8St6gN-Pna"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent"
      ],
      "metadata": {
        "id": "ukQrvYeY-YsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.agent.llm_chain.prompt.template"
      ],
      "metadata": {
        "id": "A_XDRBVV-fdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"how many rows are in the dataset?\")"
      ],
      "metadata": {
        "id": "UThv_i61-9Ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyze ADO Backlog CSV Data"
      ],
      "metadata": {
        "id": "hoLfId_PKADm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"how many bugs and how many user stories are there?\")"
      ],
      "metadata": {
        "id": "59A5A-wi_CWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"how many sprints?\")"
      ],
      "metadata": {
        "id": "7JyQe1ld_KoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"how many assignees?\")"
      ],
      "metadata": {
        "id": "dhPyh7Gp_Sik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"which assignee has the most user stories assigned each sprint\")"
      ],
      "metadata": {
        "id": "mjGIuWQ8BT8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"resolved cycle time equals the number of days between the activated date and resolved date, including the activated date and resolved date. what is the average cycle time per sprint?\")"
      ],
      "metadata": {
        "id": "NC58nF5jBlHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"list the average cycle time for each sprint\")"
      ],
      "metadata": {
        "id": "C71VwkhfDGvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"which assignee on average has the highest cycle time resolved per sprint\")"
      ],
      "metadata": {
        "id": "2p4gl2KVDURx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"list the cycle time of {assignee name} each sprint\")"
      ],
      "metadata": {
        "id": "q0j8A3oODlp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"list the cycle time of {assignee name} each sprint. include the sprint name, and work item type\")"
      ],
      "metadata": {
        "id": "-hda9IFwD6u1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"on average how many items are resolved per sprint\")"
      ],
      "metadata": {
        "id": "4ZsE4o6SJWW1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
